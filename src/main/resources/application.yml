server:
  port: 8081

app:
  kafka:
    topic: gh-repositories-prod-new
  elastic:
    index: gh-repositories-prod-new
    bulk-chunk: 2000

spring:
  application:
    name: gh-consumer

  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS}

    consumer:
      client-id: gh-consumer
      group-id: gh-repositories-es-sink-local-20251213-10
      enable-auto-commit: false
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      max-poll-records: 2000

    listener:
      type: batch
      ack-mode: manual

    properties:
      security.protocol: SASL_SSL
      sasl.mechanism: SCRAM-SHA-512
      sasl.jaas.config: >-
        org.apache.kafka.common.security.scram.ScramLoginModule required
        username=${KAFKA_USERNAME}
        password=${KAFKA_PASSWORD};
      ssl.truststore.location: ${KAFKA_TRUSTSTORE_PATH}
      ssl.truststore.type: PEM
      fetch.max.bytes: 52428800
      max.partition.fetch.bytes: 10485760
      fetch.min.bytes: 1048576
      fetch.max.wait.ms: 500

elastic:
  url: ${ELASTIC_URL:http://localhost:9200}

logging:
  level:
    root: INFO
    com.consumer.gh_consumer: INFO
    org.springframework.kafka: INFO
    org.apache.kafka.clients.NetworkClient: WARN
    org.apache.kafka.clients.consumer.internals.ConsumerCoordinator: WARN